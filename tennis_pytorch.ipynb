{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e557514",
   "metadata": {},
   "source": [
    "# ATP match prediction (PyTorch, **no embeddings**)\n",
    "\n",
    "Denne notebook viser en *embedding-fri* baseline, hvor vi:\n",
    "- loader ATP-match CSV'er (fx `atp_matches/atp_matches_2000.csv` ... `atp_matches_2024.csv`)\n",
    "- laver **player1/player2**-eksempler + label (1 hvis player1 vinder)\n",
    "- beregner **performance sidste 3 kampe** *kun ud fra tidligere kampe* (ingen leakage)\n",
    "- one-hot encoder kategorier (surface, level, lande) og standardiserer numeriske features\n",
    "- træner en 2-lags MLP (TwoLayerNet-stil) med `BCEWithLogitsLoss`\n",
    "\n",
    "> Split: train = 2000–2023, test = 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "b15c6075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#importere bare filer her og vælger device\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f374717",
   "metadata": {},
   "source": [
    "## 1) Load data\n",
    "\n",
    "min struktur:\n",
    "```\n",
    "projekt uge/\n",
    "  atp_matches/\n",
    "    atp_matches_2000.csv\n",
    "    ...\n",
    "    atp_matches_2023.csv\n",
    "  atp_matches_2024.csv\n",
    "\n",
    "Hvis jere filer hedder noget andet, justér `load_matches(...)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "e46e3f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71830, 49),\n",
       " Index(['tourney_id', 'tourney_name', 'surface', 'draw_size', 'tourney_level',\n",
       "        'tourney_date', 'match_num', 'winner_id', 'winner_seed', 'winner_entry',\n",
       "        'winner_name', 'winner_hand', 'winner_ht', 'winner_ioc', 'winner_age',\n",
       "        'loser_id', 'loser_seed', 'loser_entry', 'loser_name', 'loser_hand'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en function som gå in i mappen atp_matches \n",
    "def load_matches(folder=\"atp_matches\"):\n",
    "    folder = Path(folder)\n",
    "    all_dfs = []\n",
    "\n",
    "    #et for loop og function som går igennem alle csv filer i mappen\n",
    "    for f in sorted(folder.glob(\"*.csv\")):\n",
    "        df = pd.read_csv(f)\n",
    "        df[\"tourney_date\"] = df[\"tourney_date\"].astype(int)\n",
    "        all_dfs.append(df)\n",
    "    out = pd.concat(all_dfs, ignore_index=True)\n",
    "    return out\n",
    "\n",
    "df = load_matches(\"atp_matches\")\n",
    "df.shape, df.columns[:20]\n",
    "\n",
    "# printet ses en index med alle de forsekllige emner som er columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c198b5",
   "metadata": {},
   "source": [
    "## 2) Sortér kronologisk + beregn *sidste 3 kampe* performance\n",
    "\n",
    "Vi skal sikre at \"sidste 3\" kun bruger **kampe før den aktuelle kamp**.\n",
    "Vi sorterer derfor efter `tourney_date` og `match_num` (hvis findes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "7f99eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funktion der altså udregner vores last_3, last_10, og surf_last_10 parametre\n",
    "def add_form_features(df: pd.DataFrame, k_short: int = 3, k_long: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"Beregn pre-match form-features uden leakage.\n",
    "\n",
    "    Vi gemmer én historik pr spiller (maxlen=k_long) og tager så last-k_short fra den.\n",
    "    Surface-form gemmes separat pr (spiller, surface) med maxlen=k_long.\n",
    "    \"\"\"\n",
    "    df = df.sort_values([\"tourney_date\", \"match_num\"] if \"match_num\" in df.columns else [\"tourney_date\"],\n",
    "                        kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    hist = defaultdict(lambda: deque(maxlen=k_long))                 # player -> last results (0/1)\n",
    "    hist_surf = defaultdict(lambda: deque(maxlen=k_long))            # (player, surface) -> last results\n",
    "\n",
    "    \n",
    "    # opretter lister for hvor mange sejre sidste (3,10) games, hvor mange tabte og hvor mange spillet\n",
    "    w_last3_wr, w_last3_n = [], []\n",
    "    l_last3_wr, l_last3_n = [], []\n",
    "    w_last10_wr, w_last10_n = [], []\n",
    "    l_last10_wr, l_last10_n = [], []\n",
    "    w_slast10_wr, w_slast10_n = [], []\n",
    "    l_slast10_wr, l_slast10_n = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        wid, lid = row[\"winner_id\"], row[\"loser_id\"]\n",
    "        surf = row.get(\"surface\") or \"UNK\"\n",
    "        if pd.isna(surf):\n",
    "            surf = \"UNK\"\n",
    "\n",
    "        wh = hist[wid]\n",
    "        lh = hist[lid]\n",
    "\n",
    "        # last3 (fra last10 deque)\n",
    "        wh3 = list(wh)[-k_short:]\n",
    "        lh3 = list(lh)[-k_short:]\n",
    "        # winrate calculations\n",
    "        w_last3_n.append(len(wh3)); w_last3_wr.append((sum(wh3) / len(wh3)) if wh3 else 0.0)\n",
    "        l_last3_n.append(len(lh3)); l_last3_wr.append((sum(lh3) / len(lh3)) if lh3 else 0.0)\n",
    "\n",
    "        # last10 (hele deque)\n",
    "        # winrate calculations\n",
    "        w_last10_n.append(len(wh)); w_last10_wr.append((sum(wh) / len(wh)) if wh else 0.0)\n",
    "        l_last10_n.append(len(lh)); l_last10_wr.append((sum(lh) / len(lh)) if lh else 0.0)\n",
    "\n",
    "        # surface last10\n",
    "        wsh = hist_surf[(wid, surf)]\n",
    "        lsh = hist_surf[(lid, surf)]\n",
    "        # winrate calculations\n",
    "        w_slast10_n.append(len(wsh)); w_slast10_wr.append((sum(wsh) / len(wsh)) if wsh else 0.0)\n",
    "        l_slast10_n.append(len(lsh)); l_slast10_wr.append((sum(lsh) / len(lsh)) if lsh else 0.0)\n",
    "\n",
    "        # opdatér historik efter vi har læst features\n",
    "        wh.append(1); lh.append(0)\n",
    "        wsh.append(1); lsh.append(0)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"winner_last3_n\"] = w_last3_n  # er antal kampe spillet maks 3\n",
    "    out[\"winner_last3_wr\"] = w_last3_wr  # er antal vundede kampe ud af de 3\n",
    "    out[\"loser_last3_n\"] = l_last3_n   # antal kampe modstandere har vundet ud af de 3\n",
    "    out[\"loser_last3_wr\"] = l_last3_wr   # antal kampe modstandere har spillet maks 3\n",
    "\n",
    "    out[\"winner_last10_n\"] = w_last10_n\n",
    "    out[\"winner_last10_wr\"] = w_last10_wr\n",
    "    out[\"loser_last10_n\"] = l_last10_n\n",
    "    out[\"loser_last10_wr\"] = l_last10_wr\n",
    "\n",
    "    out[\"winner_surf_last10_n\"] = w_slast10_n\n",
    "    out[\"winner_surf_last10_wr\"] = w_slast10_wr\n",
    "    out[\"loser_surf_last10_n\"] = l_slast10_n\n",
    "    out[\"loser_surf_last10_wr\"] = l_slast10_wr\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf4a69",
   "metadata": {},
   "source": [
    "Her udregnes ELO, både overordnet ELO og surface sepcefik ELO som hænger sammen med parametren \"surface\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "48c3ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elo_features(\n",
    "    df: pd.DataFrame,\n",
    "    base: float = 1500.0,\n",
    "    rho: float = 0.85,\n",
    "    k_by_year = None,\n",
    "    k_default_global: float = 48.0,\n",
    "    k_default_surface: float = 32.0,\n",
    "    k_surface_scale: float = 0.70,\n",
    "    use_best_of: bool = True,\n",
    "    use_level: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    #Season reset ved årsskifte: elo = base + rho*(elo-base)\n",
    "    #K kan afhænge af år + justeres af best_of og turneringsniveau\n",
    "    df = df.sort_values([\"tourney_date\", \"match_num\"] if \"match_num\" in df.columns else [\"tourney_date\"],\n",
    "                        kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    if k_by_year is None:\n",
    "        # nyere kampe vægtes højere\n",
    "        k_by_year = [(2022, 64.0), (2018, 48.0), (2010, 40.0), (2000, 32.0)]\n",
    "\n",
    "    def K_for_year(year: int, default_k: float) -> float:\n",
    "        for y0, kval in k_by_year:\n",
    "            if year >= y0:\n",
    "                return float(kval)\n",
    "        return float(default_k)\n",
    "\n",
    "    def best_of_mult(row) -> float:\n",
    "        if not use_best_of:\n",
    "            return 1.0\n",
    "        try:\n",
    "            bo = int(row.get(\"best_of\", 3))\n",
    "        except Exception:\n",
    "            return 1.0\n",
    "        return 1.10 if bo >= 5 else 1.0\n",
    "\n",
    "    def level_mult(row) -> float:\n",
    "        if not use_level:\n",
    "            return 1.0\n",
    "        lvl = row.get(\"tourney_level\", None)\n",
    "        return {\"G\": 1.10, \"M\": 1.05, \"A\": 1.02, \"B\": 1.00}.get(str(lvl), 1.0)\n",
    "\n",
    "    elo_g = defaultdict(lambda: float(base))\n",
    "    elo_s = defaultdict(lambda: float(base))  # (player, surface) -> elo\n",
    "\n",
    "    current_year = None\n",
    "    w_g_pre, l_g_pre = [], []\n",
    "    w_s_pre, l_s_pre = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        y = int(row[\"tourney_date\"]) // 10000\n",
    "        if current_year is None:\n",
    "            current_year = y\n",
    "        elif y != current_year:\n",
    "            # season reset\n",
    "            for pid in list(elo_g.keys()):\n",
    "                elo_g[pid] = base + rho * (elo_g[pid] - base)\n",
    "            for key in list(elo_s.keys()):\n",
    "                elo_s[key] = base + rho * (elo_s[key] - base)\n",
    "            current_year = y\n",
    "\n",
    "        wid, lid = row[\"winner_id\"], row[\"loser_id\"]\n",
    "        surf = row.get(\"surface\") or \"UNK\"\n",
    "        if pd.isna(surf):\n",
    "            surf = \"UNK\"\n",
    "\n",
    "        # global pre\n",
    "        egw, egl = elo_g[wid], elo_g[lid]\n",
    "        w_g_pre.append(egw); l_g_pre.append(egl)\n",
    "\n",
    "        p_w = 1.0 / (1.0 + 10 ** ((egl - egw) / 400.0))    # formel for at udregne sandsynligheden for den med højest ELO vinder. \n",
    "        K_g = K_for_year(y, k_default_global) * best_of_mult(row) * level_mult(row)  #her er hvor den finder hvor stor en ændring i ELO der skal laves\n",
    "        elo_g[wid] = egw + K_g * (1 - p_w)  # Her opdatere den så endeligt ELO for vinder og nedenunder taber\n",
    "        elo_g[lid] = egl + K_g * (0 - (1 - p_w))\n",
    "\n",
    "        # surface pre\n",
    "        esw, esl = elo_s[(wid, surf)], elo_s[(lid, surf)]\n",
    "        w_s_pre.append(esw); l_s_pre.append(esl)\n",
    "\n",
    "        p_sw = 1.0 / (1.0 + 10 ** ((esl - esw) / 400.0))\n",
    "        K_s = K_for_year(y, k_default_surface) * k_surface_scale * best_of_mult(row) * level_mult(row)\n",
    "        elo_s[(wid, surf)] = esw + K_s * (1 - p_sw)\n",
    "        elo_s[(lid, surf)] = esl + K_s * (0 - (1 - p_sw))\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"winner_elo_pre\"] = w_g_pre\n",
    "    out[\"loser_elo_pre\"] = l_g_pre\n",
    "    out[\"winner_surfelo_pre\"] = w_s_pre\n",
    "    out[\"loser_surfelo_pre\"] = l_s_pre\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b06a6",
   "metadata": {},
   "source": [
    "## 3) Byg et rigtigt supervised datasæt (player1 vs player2)\n",
    "\n",
    "Vigtig pointe: hvis du bruger rækkerne direkte (\"winner_*\" og \"loser_*\"), så er label altid 1 → modellen lærer intet.\n",
    "\n",
    "Løsning: lav **to** eksempler pr. kamp:\n",
    "- (player1 = winner, player2 = loser, y=1)\n",
    "- (player1 = loser, player2 = winner, y=0)\n",
    "\n",
    "Så får du et balanceret datasæt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "d04e5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_pairwise_dataset(df):\n",
    "    base = df.copy()\n",
    "\n",
    "    # feature-kilder (kun pre-match features!)\n",
    "    # OBS: brug IKKE w_ace, w_svpt osv. (det er efter-match stats = leakage)\n",
    "    # parametre om spillerne som bruges i modellen\n",
    "    cols_p = {\n",
    "        \"age\": (\"winner_age\", \"loser_age\"),\n",
    "        \"ht\": (\"winner_ht\", \"loser_ht\"),\n",
    "        \"rank\": (\"winner_rank\", \"loser_rank\"),\n",
    "        \"rank_points\": (\"winner_rank_points\", \"loser_rank_points\"),\n",
    "        \"ioc\": (\"winner_ioc\", \"loser_ioc\"),\n",
    "        \"hand\": (\"winner_hand\", \"loser_hand\"),\n",
    "        \"last3_wr\": (\"winner_last3_wr\", \"loser_last3_wr\"),\n",
    "        \"last3_n\": (\"winner_last3_n\", \"loser_last3_n\"),\n",
    "        \"elo\": (\"winner_elo_pre\", \"loser_elo_pre\"),\n",
    "        \"surfelo\": (\"winner_surfelo_pre\", \"loser_surfelo_pre\"),\n",
    "        \"last10_wr\": (\"winner_last10_wr\", \"loser_last10_wr\"),\n",
    "        \"last10_n\":  (\"winner_last10_n\",  \"loser_last10_n\"),\n",
    "        \"surf_last10_wr\": (\"winner_surf_last10_wr\", \"loser_surf_last10_wr\"),\n",
    "        \"surf_last10_n\":  (\"winner_surf_last10_n\",  \"loser_surf_last10_n\"),\n",
    "\n",
    "    }\n",
    "\n",
    "    # match-level features, parametre om turneringen som bruges i modellen. \n",
    "    MATCH_COLS = [\"surface\", \"tourney_level\", \"best_of\", \"round\", \"tourney_date\", ]\n",
    "    match_cols = [c for c in MATCH_COLS if c in base.columns]\n",
    "    out = base[match_cols].copy()\n",
    "\n",
    "\n",
    "    def make_view(swap=False):\n",
    "        out = pd.DataFrame()\n",
    "        # match features kopieres over i out\n",
    "        for c in match_cols:\n",
    "            out[c] = base[c]\n",
    "\n",
    "        # Her gør vi modellen uafhængig fra vinder og taber. men til player 1 og player 2. \n",
    "        # trikket er både at køre dataen på at p1 vinder og at p1 taber ved at bytte på player id. \n",
    "        # så den stadig ved hvem der vandt men ved ikke at det er id nr 1 hver gang. \n",
    "        for name, (cw, cl) in cols_p.items():\n",
    "            if swap:\n",
    "                out[f\"p1_{name}\"] = base[cl]\n",
    "                out[f\"p2_{name}\"] = base[cw]\n",
    "            else:\n",
    "                out[f\"p1_{name}\"] = base[cw]\n",
    "                out[f\"p2_{name}\"] = base[cl]\n",
    "\n",
    "        out[\"p1_id\"] = base[\"loser_id\"] if swap else base[\"winner_id\"]\n",
    "        out[\"p2_id\"] = base[\"winner_id\"] if swap else base[\"loser_id\"]\n",
    "        # y værdien brugt i swap y=1 betyder p1 vandt med swap=False, ved swap=True er y=0 p1 vandt.\n",
    "        # derfor gætter modellen ikke bare y=1 hver gang. \n",
    "        out[\"y\"] = 0 if swap else 1\n",
    "        return out\n",
    "\n",
    "    a = make_view(swap=False)\n",
    "    b = make_view(swap=True)\n",
    "    out = pd.concat([a,b], ignore_index=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad596b",
   "metadata": {},
   "source": [
    "## 4) Train/test split (2000–2023 / 2024)\n",
    "\n",
    "Vi udleder år fra `tourney_date` (format YYYYMMDD).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cbefca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_MODE=houston | train matches=71830 | test matches=27 | train rows=143660 | test rows=54\n"
     ]
    }
   ],
   "source": [
    "EVAL_MODE = \"houston\"   # her vælger du ift hvad modellen skal teste på du kan indtaste disse valgmuligheder: \"wimbledon\", \"full2024\", \"canadian\", \"estoril\", \"miami\", \"marrakech\"\n",
    "\n",
    "PATH_WIM  = \"2024_wimbeldon.csv\"\n",
    "PATH_2024 = \"atp_matches_2024.csv\"\n",
    "PATH_CAN  = \"canadian_open.csv\"   \n",
    "PATH_EST = \"estoril_open_2024_with_bet365.csv\"\n",
    "PATH_HOU = \"houston_open_2024_with_bet365.csv\"\n",
    "PATH_MIA = \"Miami_odds.csv\"\n",
    "PATH_MAR = \"marrakech_open_2024_with_bet365.csv\"\n",
    "\n",
    "# load historik\n",
    "df_all = load_matches(\"atp_matches\")\n",
    "df_all[\"tourney_date\"] = df_all[\"tourney_date\"].astype(int)\n",
    "\n",
    "# vælg test raw (uden odds)\n",
    "if EVAL_MODE == \"wimbledon\":\n",
    "    df_test_raw = pd.read_csv(PATH_WIM)\n",
    "elif EVAL_MODE == \"full2024\":\n",
    "    df_test_raw = pd.read_csv(PATH_2024)\n",
    "elif EVAL_MODE == \"canadian\":\n",
    "    df_test_raw = pd.read_csv(PATH_CAN)\n",
    "elif EVAL_MODE == \"estoril\":\n",
    "    df_test_raw = pd.read_csv(PATH_EST)\n",
    "elif EVAL_MODE == \"houston\":\n",
    "    df_test_raw = pd.read_csv(PATH_HOU)\n",
    "elif EVAL_MODE == \"miami\":\n",
    "    df_test_raw = pd.read_csv(PATH_MIA)\n",
    "elif EVAL_MODE == \"marrakech\":\n",
    "    df_test_raw = pd.read_csv(PATH_MAR)\n",
    "else:\n",
    "    raise ValueError(\"EVAL_MODE skal være 'wimbledon', 'full2024' eller 'canadian'\")\n",
    "\n",
    "df_test_raw[\"tourney_date\"] = df_test_raw[\"tourney_date\"].astype(int)\n",
    "\n",
    "# kombiner for at få pre-match features (sort stabilt)\n",
    "df = pd.concat([df_all, df_test_raw], ignore_index=True)\n",
    "df = df.sort_values([\"tourney_date\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "# nye samlede feature-funktioner\n",
    "df = add_form_features(df, k_short=3, k_long=10)\n",
    "df = add_elo_features(df, rho=0.85, k_surface_scale=0.7)\n",
    "\n",
    "# split i RAW space\n",
    "df[\"year\"] = (df[\"tourney_date\"] // 10000).astype(int)\n",
    "train_raw = df[df[\"year\"].between(2000, 2023)].copy()\n",
    "\n",
    "if EVAL_MODE in (\"wimbledon\", \"canadian\"):\n",
    "    # samme match-logik som før\n",
    "    if \"tourney_id\" in df_test_raw.columns and \"tourney_id\" in df.columns:\n",
    "        ids = set(df_test_raw[\"tourney_id\"].astype(str).unique())\n",
    "        test_raw = df[df[\"tourney_id\"].astype(str).isin(ids)].copy()\n",
    "    elif \"tourney_name\" in df_test_raw.columns and \"tourney_name\" in df.columns:\n",
    "        keys = set(zip(df_test_raw[\"tourney_name\"].astype(str),\n",
    "                       df_test_raw[\"tourney_date\"].astype(int)))\n",
    "        mask = [k in keys for k in zip(df[\"tourney_name\"].astype(str),\n",
    "                                       df[\"tourney_date\"].astype(int))]\n",
    "        test_raw = df[pd.Series(mask, index=df.index)].copy()\n",
    "    else:\n",
    "        raise ValueError(\"Kan ikke matche test-turnering: mangler tourney_id og tourney_name.\")\n",
    "else:\n",
    "    test_raw = df[df[\"year\"] == 2024].copy()\n",
    "\n",
    "# byg pairwise separat (samme som før)\n",
    "train_df = build_pairwise_dataset(train_raw).reset_index(drop=True)\n",
    "test_df  = build_pairwise_dataset(test_raw).reset_index(drop=True)\n",
    "\n",
    "print(\n",
    "    f\"EVAL_MODE={EVAL_MODE} | train matches={len(train_raw)} | test matches={len(test_raw)} | \"\n",
    "    f\"train rows={len(train_df)} | test rows={len(test_df)}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "7d27ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elo_diff_features(df):\n",
    "    # diff features\n",
    "    df[\"diff_elo\"]      = df[\"p1_elo\"]      - df[\"p2_elo\"]\n",
    "    df[\"diff_surfelo\"]  = df[\"p1_surfelo\"]  - df[\"p2_surfelo\"]\n",
    "\n",
    "    # elo win-prob (vectoriseret)\n",
    "    df[\"elo_p\"]      = 1.0 / (1.0 + np.power(10.0, -df[\"diff_elo\"]     / 400.0))\n",
    "    df[\"surfelo_p\"]  = 1.0 / (1.0 + np.power(10.0, -df[\"diff_surfelo\"] / 400.0))\n",
    "    return df\n",
    "\n",
    "train_df = add_elo_diff_features(train_df)\n",
    "test_df  = add_elo_diff_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d32ade",
   "metadata": {},
   "source": [
    "## 5) Preprocessing uden embeddings\n",
    "\n",
    "- **Kategorier**: one-hot (surface, tourney_level, round, hand, ioc)\n",
    "- **Dato**: brug fx *år* og *dag-i-året* i stedet for rå YYYYMMDD\n",
    "- **Numeriske**: fill NaN + standardiser (fit på train)\n",
    "\n",
    "> OBS: Player-ID som one-hot kan gøre modellen stor og “memoriserende”. Start uden ID; tilføj først hvis nødvendigt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "b2e1f1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143660, 280), (54, 280))"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- date-features ----------\n",
    "def add_date_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    d = pd.to_datetime(\n",
    "        df[\"tourney_date\"].astype(int).astype(str),\n",
    "        format=\"%Y%m%d\",\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "    df[\"date_year\"] = d.dt.year.fillna(0).astype(int)\n",
    "    df[\"date_doy\"]  = d.dt.dayofyear.fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "train_df = add_date_features(train_df)\n",
    "test_df  = add_date_features(test_df)\n",
    "\n",
    "# ---------- diffs (spillerfeatures) ----------\n",
    "DIFF_BASE = [\n",
    "    \"age\", \"ht\", \"rank\", \"rank_points\",\n",
    "    \"last3_wr\", \"last3_n\",\n",
    "    \"elo\", \"surfelo\",\n",
    "    \"last10_wr\", \"last10_n\",\n",
    "    \"surf_last10_wr\", \"surf_last10_n\",\n",
    "]\n",
    "\n",
    "def add_diff_features(df: pd.DataFrame, cols=DIFF_BASE) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in cols:\n",
    "        df[f\"diff_{c}\"] = df[f\"p1_{c}\"] - df[f\"p2_{c}\"]\n",
    "    return df\n",
    "\n",
    "train_df = add_diff_features(train_df)\n",
    "test_df  = add_diff_features(test_df)\n",
    "\n",
    "\n",
    "def add_elo_prob_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"elo_p\"]     = 1.0 / (1.0 + np.power(10.0, -df[\"diff_elo\"]     / 400.0))\n",
    "    df[\"surfelo_p\"] = 1.0 / (1.0 + np.power(10.0, -df[\"diff_surfelo\"] / 400.0))\n",
    "    return df\n",
    "\n",
    "train_df = add_elo_prob_features(train_df)\n",
    "test_df  = add_elo_prob_features(test_df)\n",
    "\n",
    "# ---------- feature-valg ----------\n",
    "use_player_id_onehot = False  # True hvis du vil one-hot p1_id/p2_id\n",
    "\n",
    "cat_cols = [\n",
    "    \"surface\", \"tourney_level\", \"best_of\", \"round\",\n",
    "    \"p1_ioc\", \"p2_ioc\", \"p1_hand\", \"p2_hand\",\n",
    "]\n",
    "if use_player_id_onehot:\n",
    "    cat_cols += [\"p1_id\", \"p2_id\"]\n",
    "\n",
    "\n",
    "\n",
    "num_cols = [\n",
    "    \"diff_age\",\"diff_ht\",\"diff_rank\",\"diff_rank_points\",\n",
    "    \"diff_last3_wr\",\"diff_last3_n\",\n",
    "    \"diff_elo\",\"diff_surfelo\",\n",
    "    \"elo_p\",\"surfelo_p\",\n",
    "    \"date_year\",\"date_doy\",\n",
    "    \"diff_last10_wr\",\"diff_last10_n\",\n",
    "    \"diff_surf_last10_wr\",\"diff_surf_last10_n\",\n",
    "]\n",
    "\n",
    "# ---------- NaN-handling ----------\n",
    "for c in cat_cols:\n",
    "    train_df[c] = train_df[c].fillna(\"UNK\").astype(str)\n",
    "    test_df[c]  = test_df[c].fillna(\"UNK\").astype(str)\n",
    "\n",
    "for c in num_cols:\n",
    "    train_df[c] = pd.to_numeric(train_df[c], errors=\"coerce\")\n",
    "    test_df[c]  = pd.to_numeric(test_df[c],  errors=\"coerce\")\n",
    "\n",
    "# fyld numeric NaN med train-median (samme median bruges på test)\n",
    "train_medians = train_df[num_cols].median(numeric_only=True)\n",
    "train_df[num_cols] = train_df[num_cols].fillna(train_medians)\n",
    "test_df[num_cols]  = test_df[num_cols].fillna(train_medians)\n",
    "\n",
    "# ---------- One-hot ----------\n",
    "train_cat = pd.get_dummies(train_df[cat_cols], prefix=cat_cols)\n",
    "test_cat  = pd.get_dummies(test_df[cat_cols],  prefix=cat_cols)\n",
    "\n",
    "# align test til train-kolonner\n",
    "test_cat = test_cat.reindex(columns=train_cat.columns, fill_value=0)\n",
    "\n",
    "\n",
    "# ---------- Standardisering (fit på train) ----------\n",
    "mu = train_df[num_cols].mean()\n",
    "sd = train_df[num_cols].std().replace(0, 1.0)\n",
    "\n",
    "train_num = (train_df[num_cols] - mu) / sd\n",
    "test_num  = (test_df[num_cols]  - mu) / sd\n",
    "\n",
    "# ---------- X/y ----------\n",
    "X_train = pd.concat([train_num, train_cat], axis=1).astype(np.float32)\n",
    "X_test  = pd.concat([test_num,  test_cat],  axis=1).astype(np.float32)\n",
    "\n",
    "y_train = train_df[\"y\"].astype(np.float32).values\n",
    "y_test  = test_df[\"y\"].astype(np.float32).values\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523980c",
   "metadata": {},
   "source": [
    "## 6) PyTorch Dataset + DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "2ceaa3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 280])"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TennisDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # X kan være DataFrame eller numpy array\n",
    "        if hasattr(X, \"to_numpy\"):\n",
    "            X = X.to_numpy(dtype=np.float32, copy=False)\n",
    "        else:\n",
    "            X = np.asarray(X, dtype=np.float32)\n",
    "\n",
    "        y = np.asarray(y, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 4096  # justér efter RAM/GPU\n",
    "train_ds = TennisDataset(X_train, y_train)\n",
    "test_ds  = TennisDataset(X_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "next(iter(train_loader))[0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e7db3",
   "metadata": {},
   "source": [
    "## 7) TwoLayerNet-lignende model (binary classification)\n",
    "\n",
    "Output er **logits** (ingen sigmoid i forward), og vi bruger `BCEWithLogitsLoss`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "e0e04d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=280, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ryddet MLP (logits output)\n",
    "class MLP(nn.Module):\n",
    "    _ACTS = {\n",
    "        \"silu\": nn.SiLU,\n",
    "        \"gelu\": nn.GELU,\n",
    "        \"lrelu\": lambda: nn.LeakyReLU(0.01),\n",
    "        \"relu\": nn.ReLU,\n",
    "    }\n",
    "\n",
    "    def __init__(self, D_in: int, H: int = 128, dropout: float = 0.2, act: str = \"gelu\"):\n",
    "        super().__init__()\n",
    "        act_layer = self._ACTS.get(act, nn.ReLU)\n",
    "        act_layer = act_layer() if callable(act_layer) else nn.ReLU()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.BatchNorm1d(H),\n",
    "            act_layer,\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(H, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # logits\n",
    "\n",
    "\n",
    "D_in = X_train.shape[1]\n",
    "model = MLP(D_in, H=256, dropout=0.2, act=\"gelu\").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14742a08",
   "metadata": {},
   "source": [
    "## 8) Train + eval loops (accuracy + logloss)\n",
    "\n",
    "Accuracy er fin som start, men logloss fortæller mere om sandsynlighederne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "40a5c379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.6036 | test_loss=0.6633 | test_acc@0.50=0.6667\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    total_loss, correct, n = 0.0, 0, 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        preds = (torch.sigmoid(logits) >= threshold).float()\n",
    "        correct += (preds == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "\n",
    "    return total_loss / n, correct / n\n",
    "\n",
    "\n",
    "def train(model, train_loader, test_loader, epochs=10, threshold=0.5):\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running, n = 0.0, 0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running += loss.item() * xb.size(0)\n",
    "            n += xb.size(0)\n",
    "\n",
    "        train_loss = running / n\n",
    "        test_loss, test_acc = evaluate(model, test_loader, threshold=threshold)\n",
    "        print(\n",
    "            f\"Epoch {ep:02d} | train_loss={train_loss:.4f} | \"\n",
    "            f\"test_loss={test_loss:.4f} | test_acc@{threshold:.2f}={test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "pos = float((y_train == 1).sum())\n",
    "neg = float((y_train == 0).sum())\n",
    "if pos > 0:\n",
    "    pos_weight = torch.tensor([neg / pos], device=device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "train(model, train_loader, test_loader, epochs=1, threshold=0.50)\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd6412",
   "metadata": {},
   "source": [
    "Tager kun data med >80 sikkerhed med i målingen af acc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "d4fc8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_high_conf(model, loader, conf_thr=0.80, pred_thr=0.50):\n",
    "    model.eval()\n",
    "    correct = kept = total = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        y = yb.to(device).view(-1).float()\n",
    "\n",
    "        p = torch.sigmoid(model(xb)).view(-1)\n",
    "        preds = (p >= pred_thr).float()\n",
    "\n",
    "        conf = torch.maximum(p, 1.0 - p)          \n",
    "        mask = conf >= conf_thr\n",
    "\n",
    "        k = int(mask.sum().item())\n",
    "        kept += k\n",
    "        total += y.numel()\n",
    "\n",
    "        if k:\n",
    "            correct += int((preds[mask] == y[mask]).sum().item())\n",
    "\n",
    "    coverage = kept / total if total else 0.0\n",
    "    acc = correct / kept if kept else float(\"nan\")\n",
    "    return acc, coverage, kept, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "2423c261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr=0.50 | acc=0.6667 | coverage=100.00% (54/54)\n",
      "thr=0.52 | acc=0.6905 | coverage=77.78% (42/54)\n",
      "thr=0.60 | acc=0.7222 | coverage=33.33% (18/54)\n",
      "thr=0.70 | acc=0.5000 | coverage=7.41% (4/54)\n",
      "thr=0.80 | acc=nan | coverage=0.00% (0/54)\n",
      "thr=0.85 | acc=nan | coverage=0.00% (0/54)\n",
      "thr=0.90 | acc=nan | coverage=0.00% (0/54)\n"
     ]
    }
   ],
   "source": [
    "for thr in [0.5, 0.5236, 0.60, 0.70, 0.80, 0.85, 0.90]:\n",
    "    acc, cov, kept, total = evaluate_high_conf(model, test_loader, conf_thr=thr)\n",
    "    print(f\"thr={thr:.2f} | acc={acc:.4f} | coverage={cov:.2%} ({kept}/{total})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b7648c",
   "metadata": {},
   "source": [
    "Hurtig konfidens udregning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "cc8f60da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.52 %\n",
      "63.822149619618386 67.17914561087967\n",
      "Accuracy: 69.13 %\n",
      "67.33101292133955 70.87277731972134\n",
      "Accuracy: 66.81 %\n",
      "67.33101292133955 70.87277731972134\n"
     ]
    }
   ],
   "source": [
    "def CI(acc, n, z=1.96):\n",
    "    p = acc\n",
    "    center = (p + (z**2)/(2*n)) / (1 + (z**2)/n)\n",
    "    half = (z * math.sqrt((p*(1-p)/n) + (z**2)/(4*n**2))) / (1 + (z**2)/n)\n",
    "    return center - half, center + half\n",
    "\n",
    "# For vores model med alle gæt\n",
    "l, h = CI(0.6552, 3077)\n",
    "print(f\"Accuracy:\",(0.6552*100),\"%\")\n",
    "print((l*100), (h*100))\n",
    "\n",
    "# For Bet365\n",
    "l2, h2 = CI(0.6913, 2611)\n",
    "print(f\"Accuracy:\", (0.6913*100),\"%\")\n",
    "print((l2*100), (h2*100))\n",
    "\n",
    "# For vores model med kun gæt når sikkerhed >=52.36\n",
    "l3, h3 = CI(0.6681, 3077)\n",
    "print(\"Accuracy:\",(0.6681*100),\"%\")\n",
    "print((l2*100), (h2*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7841e7",
   "metadata": {},
   "source": [
    "Konfidens interval for ELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "598385d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline acc (combo w=0.45): 0.6296296296296297\n",
      "0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "w = 0.45  # manuelt gættet gennem forsøg\n",
    "score1 = w*test_df[\"p1_surfelo\"].values + (1-w)*test_df[\"p1_elo\"].values\n",
    "score2 = w*test_df[\"p2_surfelo\"].values + (1-w)*test_df[\"p2_elo\"].values\n",
    "\n",
    "pred_combo = (score1 >= score2).astype(int)\n",
    "acc_combo = (pred_combo == test_df[\"y\"].values).mean()\n",
    "print(f\"Baseline acc (combo w={w}):\", acc_combo)\n",
    "\n",
    "print(acc_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "4604b0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.96296296296296 %\n",
      "61.24149588338311 64.65210217569076\n"
     ]
    }
   ],
   "source": [
    "lo, hi = CI(acc_combo, 3077)\n",
    "print(acc_combo*100,\"%\")\n",
    "print((lo*100), (hi*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1af609",
   "metadata": {},
   "source": [
    "BETTINNG  (virker ikke hvis \"full2024\" er valgt som test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "780a1f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " threshold  bets correct/total  winrate  profit_DKK       ROI  avg_conf\n",
      "    0.5000    27         18/27 0.666667       790.0  0.029259  0.584996\n",
      "    0.5236    21         14/21 0.666667       230.0  0.010952  0.607274\n",
      "    0.6000    11          8/11 0.727273       390.0  0.035455  0.648671\n",
      "    0.7000     1           0/1 0.000000     -1000.0 -1.000000  0.754410\n",
      "    0.8000     0           0/0      NaN         0.0       NaN       NaN\n",
      "    0.8500     0           0/0      NaN         0.0       NaN       NaN\n",
      "    0.9000     0           0/0      NaN         0.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "STAKE = 1000\n",
    "THRESHOLDS = [0.50, 0.5236, 0.60, 0.70, 0.80, 0.85, 0.90]\n",
    "\n",
    "# Normalisér eval mode\n",
    "EVAL_MODE = str(EVAL_MODE).strip().lower()\n",
    "\n",
    "ODDS_CSV = {\n",
    "    \"wimbeldon\": \"atp_odds_wimbeldon_2024.csv\",\n",
    "    \"wimbledon\": \"atp_odds_wimbeldon_2024.csv\",\n",
    "    \"canadian\":  \"canadian_open_odds.csv\",\n",
    "    \"estoril\":   \"estoril_open_2024_with_bet365.csv\",\n",
    "    \"houston\": \"houston_open_2024_with_bet365.csv\",\n",
    "    \"miami\": \"Miami_odds.csv\",\n",
    "    \"marrakech\": \"marrakech_open_2024_with_bet365.csv\",\n",
    "}.get(EVAL_MODE)\n",
    "\n",
    "if ODDS_CSV is None:\n",
    "    raise ValueError(\"EVAL_MODE skal være 'wimbeldon/wimbledon' eller 'canadian' eller 'estoril'.\")\n",
    "\n",
    "def make_merge_key(df):\n",
    "    td = df[\"tourney_date\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "    mn = df[\"match_num\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "    return td + \"_\" + mn\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_probs = np.concatenate([\n",
    "        torch.sigmoid(model(xb.to(device))).view(-1).cpu().numpy()\n",
    "        for xb, _ in test_loader\n",
    "    ])\n",
    "\n",
    "n_matches = len(test_raw)\n",
    "if len(all_probs) != 2 * n_matches:\n",
    "    raise ValueError(f\"Forventer 2 rækker pr kamp: probs={len(all_probs)} vs 2*n={2*n_matches}\")\n",
    "\n",
    "# BLOK-ORDER\n",
    "p_a = all_probs[:n_matches]          # swap=False\n",
    "p_b = all_probs[n_matches:]          # swap=True\n",
    "p_win = (p_a + (1.0 - p_b)) / 2.0\n",
    "\n",
    "matches = test_raw.reset_index(drop=True)\n",
    "matches[\"merge_key\"] = make_merge_key(matches)\n",
    "matches[\"p_winner_beats_loser\"] = p_win\n",
    "matches[\"confidence\"] = np.maximum(p_win, 1.0 - p_win)\n",
    "matches[\"pick_side\"] = np.where(p_win >= 0.5, \"winner\", \"loser\")\n",
    "matches[\"correct\"] = (matches[\"pick_side\"] == \"winner\").astype(int)\n",
    "\n",
    "# ---- ODDS MERGE (minimal fix) ----\n",
    "odds = pd.read_csv(ODDS_CSV)\n",
    "\n",
    "# FIX 1: rens kolonnenavne (BOM/whitespace)\n",
    "odds.columns = odds.columns.str.replace(\"\\ufeff\", \"\", regex=False).str.strip()\n",
    "\n",
    "odds[\"merge_key\"] = make_merge_key(odds)\n",
    "odds = odds.drop_duplicates(\"merge_key\")\n",
    "\n",
    "matches = matches.merge(odds[[\"merge_key\",\"winner_odds\",\"loser_odds\"]], on=\"merge_key\", how=\"left\")\n",
    "\n",
    "# FIX 2: hvis merge laver _x/_y kolonner, så normalisér tilbage til winner_odds/loser_odds\n",
    "wcol = \"winner_odds\" if \"winner_odds\" in matches.columns else (\n",
    "       \"winner_odds_y\" if \"winner_odds_y\" in matches.columns else\n",
    "       \"winner_odds_x\" if \"winner_odds_x\" in matches.columns else None)\n",
    "\n",
    "lcol = \"loser_odds\" if \"loser_odds\" in matches.columns else (\n",
    "       \"loser_odds_y\" if \"loser_odds_y\" in matches.columns else\n",
    "       \"loser_odds_x\" if \"loser_odds_x\" in matches.columns else None)\n",
    "\n",
    "if wcol is None or lcol is None:\n",
    "    raise ValueError(\n",
    "        \"Finder ikke odds-kolonner efter merge. \"\n",
    "        f\"Odds-kolonner fundet i matches: {[c for c in matches.columns if 'odds' in c.lower()]}\"\n",
    "    )\n",
    "\n",
    "matches[\"winner_odds\"] = pd.to_numeric(matches[wcol], errors=\"coerce\")\n",
    "matches[\"loser_odds\"]  = pd.to_numeric(matches[lcol], errors=\"coerce\")\n",
    "# ---- slut odds merge ----\n",
    "\n",
    "has_odds = matches[\"winner_odds\"].notna() & matches[\"loser_odds\"].notna()\n",
    "matches[\"profit_if_bet\"] = np.where(\n",
    "    ~has_odds, np.nan,\n",
    "    np.where(matches[\"pick_side\"].eq(\"winner\"),\n",
    "             np.where(matches[\"correct\"].eq(1), STAKE*(matches[\"winner_odds\"]-1.0), -STAKE),\n",
    "             -STAKE)  # loser-picks taber altid i winner/loser-format\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for thr in THRESHOLDS:\n",
    "    sel = matches[matches[\"confidence\"] >= thr].dropna(subset=[\"profit_if_bet\"])\n",
    "    if len(sel) == 0:\n",
    "        rows.append([thr, 0, \"0/0\", np.nan, 0.0, np.nan, np.nan])\n",
    "        continue\n",
    "    c = int(sel[\"correct\"].sum()); t = len(sel)\n",
    "    prof = float(sel[\"profit_if_bet\"].sum())\n",
    "    rows.append([thr, t, f\"{c}/{t}\", c/t, prof, prof/(STAKE*t), float(sel[\"confidence\"].mean())])\n",
    "\n",
    "print(pd.DataFrame(rows, columns=[\"threshold\",\"bets\",\"correct/total\",\"winrate\",\"profit_DKK\",\"ROI\",\"avg_conf\"]).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43f32d",
   "metadata": {},
   "source": [
    "Hvis man bettede på de mindste odds igennem hele turneringen. (better ikke på kaampe med lige odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "e90c2312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETS: 25\n",
      "CORRECT: 16/25  (acc=64.00%)\n",
      "NET PROFIT: -1030.00 DKK\n",
      "ROI: -4.12%\n"
     ]
    }
   ],
   "source": [
    "STAKE = 1000\n",
    "\n",
    "# Normalisér eval mode\n",
    "EVAL_MODE = str(EVAL_MODE).strip().lower()\n",
    "\n",
    "CSV_PATH = {\n",
    "    \"wimbeldon\": \"atp_odds_wimbeldon_2024.csv\",\n",
    "    \"wimbledon\": \"atp_odds_wimbeldon_2024.csv\",\n",
    "    \"canadian\":  \"canadian_open_odds.csv\",\n",
    "    \"estoril\":   \"estoril_open_2024_with_bet365.csv\",\n",
    "    \"houston\": \"houston_open_2024_with_bet365.csv\",\n",
    "    \"miami\": \"MIami_odds.csv\",\n",
    "    \"marrakech\": \"marrakech_open_2024_with_bet365.csv\",\n",
    "}.get(EVAL_MODE)\n",
    "\n",
    "if CSV_PATH is None:\n",
    "    raise ValueError(\"EVAL_MODE skal være 'wimbeldon/wimbledon' eller 'canadian' eller 'estoril'.\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Minimal fix: rens kolonnenavne (BOM/whitespace)\n",
    "df.columns = df.columns.str.replace(\"\\ufeff\", \"\", regex=False).str.strip()\n",
    "\n",
    "df[\"ow\"] = pd.to_numeric(df[\"winner_odds\"], errors=\"coerce\")\n",
    "df[\"ol\"] = pd.to_numeric(df[\"loser_odds\"],  errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"ow\",\"ol\"])\n",
    "\n",
    "df = df[df[\"ow\"] != df[\"ol\"]]                 # ingen bets ved lige odds\n",
    "\n",
    "fav_is_winner = df[\"ow\"] < df[\"ol\"]            # favorit = laveste odds\n",
    "fav_odds = np.where(fav_is_winner, df[\"ow\"], df[\"ol\"])\n",
    "net_profit = np.where(fav_is_winner, STAKE*(fav_odds-1.0), -STAKE)\n",
    "\n",
    "bets = len(df)\n",
    "correct = int(fav_is_winner.sum())\n",
    "acc = correct / bets if bets else np.nan\n",
    "profit = float(net_profit.sum())\n",
    "roi = profit / (STAKE * bets) if bets else np.nan\n",
    "\n",
    "print(f\"BETS: {bets}\")\n",
    "print(f\"CORRECT: {correct}/{bets}  (acc={acc*100:.2f}%)\")\n",
    "print(f\"NET PROFIT: {profit:.2f} DKK\")\n",
    "print(f\"ROI: {roi*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f5cf57",
   "metadata": {},
   "source": [
    "Tested profit for de forskellige turneringer ved høje thresholds for mere sikker betting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "1b12d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4390\n",
      "4810\n"
     ]
    }
   ],
   "source": [
    "Miami_profit_80 = [-120, -120, -330, -260, 50]\n",
    "Miami_profit_85= [190, 190, 190, 190, 340]\n",
    "Miami_profit_90 = [40, 40, 40, 40, 40]\n",
    "\n",
    "wimbledon_profit_80 = [4910, 4910, 5530, 5020, 5780]\n",
    "wimbledon_profit_85 = [4200, 4200, 4200, 4200, 4310]\n",
    "wimbledon_profit_90 = [90, 90, -900, 90, -860]\n",
    "\n",
    "canadian_profit_80 = [220, 220, 220, 290, 220]\n",
    "canadian_profit_85 = [160, 160, 160, 160, 0]\n",
    "canadian_profit_90 = [0, 0, 0, 0, 0]\n",
    "\n",
    "estoril_profit_80 = [250, 0, 0, 0, 250]\n",
    "estoril_profit_85 = [0, 0, 0, 0, 0]\n",
    "estoril_profit_90 = [0, 0, 0, 0, 0] \n",
    "\n",
    "marrakech_profit_80 = [0, 250, 250, 0, 0]\n",
    "marrakech_profit_85 = [0, 0, 0, 0, 0]\n",
    "marrakech_profit_90 = [0, 0, 0, 0, 0]\n",
    "\n",
    "houston_profit_80 = [0, 0, 0, 0, 0]\n",
    "houston_profit_85 = [0, 0, 0, 0, 0]\n",
    "houston_profit_90 = [0, 0, 0, 0, 0]\n",
    "\n",
    "lowest_profit_80 = 190+4200+0+0+0+0\n",
    "highest_profit_80 = 340+4310+160+0+0+0\n",
    "print(lowest_profit_80)\n",
    "print(highest_profit_80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
