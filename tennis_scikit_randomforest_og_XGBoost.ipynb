{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9afb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, classification_report, confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed49086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 74906\n",
      "Date range: 20000103 to 20241218\n"
     ]
    }
   ],
   "source": [
    "def load_matches(folder=\"atp_matches\"):\n",
    "    folder = Path(folder)\n",
    "    dfs = []\n",
    "    for f in sorted(folder.glob(\"*.csv\")):\n",
    "        df = pd.read_csv(f)\n",
    "        df[\"tourney_date\"] = df[\"tourney_date\"].astype(int)\n",
    "        dfs.append(df)\n",
    "    if not dfs:\n",
    "        raise FileNotFoundError(f\"Ingen CSV-filer fundet i {folder.resolve()}\")\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_train = load_matches(\"atp_matches\")               # 2000-2023\n",
    "df_2024  = pd.read_csv(\"atp_matches_2024.csv\")       # 2024 ligger udenfor\n",
    "df_2024[\"tourney_date\"] = df_2024[\"tourney_date\"].astype(int)\n",
    "\n",
    "df = pd.concat([df_train, df_2024], ignore_index=True)\n",
    "\n",
    "print(\"Loaded rows:\", len(df))\n",
    "print(\"Date range:\", df[\"tourney_date\"].min(), \"to\", df[\"tourney_date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f561047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features built. Example cols: ['winner_elo_pre', 'loser_elo_pre', 'winner_surfelo_pre', 'loser_surfelo_pre']\n"
     ]
    }
   ],
   "source": [
    "def add_date_features(df):\n",
    "    df = df.copy()\n",
    "    dt = pd.to_datetime(df[\"tourney_date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    df[\"date_year\"] = dt.dt.year\n",
    "    df[\"date_doy\"]  = dt.dt.dayofyear\n",
    "    return df\n",
    "\n",
    "def add_lastN_overall_and_surface(df, k=10):\n",
    "    df = df.copy()\n",
    "    sort_cols = [\"tourney_date\"] + ([\"match_num\"] if \"match_num\" in df.columns else [])\n",
    "    df = df.sort_values(sort_cols).reset_index(drop=True)\n",
    "\n",
    "    hist_overall = defaultdict(lambda: deque(maxlen=k))\n",
    "    hist_surface = defaultdict(lambda: deque(maxlen=k))\n",
    "\n",
    "    w_ov_wins, w_ov_n, l_ov_wins, l_ov_n = [], [], [], []\n",
    "    w_sf_wins, w_sf_n, l_sf_wins, l_sf_n = [], [], [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        wid, lid = row[\"winner_id\"], row[\"loser_id\"]\n",
    "        surf = str(row.get(\"surface\", \"UNK\"))\n",
    "\n",
    "        wh, lh = hist_overall[wid], hist_overall[lid]\n",
    "        w_ov_wins.append(sum(wh)); w_ov_n.append(len(wh))\n",
    "        l_ov_wins.append(sum(lh)); l_ov_n.append(len(lh))\n",
    "\n",
    "        wsh, lsh = hist_surface[(wid, surf)], hist_surface[(lid, surf)]\n",
    "        w_sf_wins.append(sum(wsh)); w_sf_n.append(len(wsh))\n",
    "        l_sf_wins.append(sum(lsh)); l_sf_n.append(len(lsh))\n",
    "\n",
    "        # update AFTER match\n",
    "        wh.append(1); lh.append(0)\n",
    "        wsh.append(1); lsh.append(0)\n",
    "\n",
    "    df[f\"winner_last{k}_wr\"] = np.array(w_ov_wins) / np.maximum(1, np.array(w_ov_n))\n",
    "    df[f\"winner_last{k}_n\"]  = w_ov_n\n",
    "    df[f\"loser_last{k}_wr\"]  = np.array(l_ov_wins) / np.maximum(1, np.array(l_ov_n))\n",
    "    df[f\"loser_last{k}_n\"]   = l_ov_n\n",
    "\n",
    "    df[f\"winner_surf_last{k}_wr\"] = np.array(w_sf_wins) / np.maximum(1, np.array(w_sf_n))\n",
    "    df[f\"winner_surf_last{k}_n\"]  = w_sf_n\n",
    "    df[f\"loser_surf_last{k}_wr\"]  = np.array(l_sf_wins) / np.maximum(1, np.array(l_sf_n))\n",
    "    df[f\"loser_surf_last{k}_n\"]   = l_sf_n\n",
    "    return df\n",
    "\n",
    "def add_global_elo(df, base=1500.0, rho=0.85):\n",
    "    df = df.copy()\n",
    "    sort_cols = [\"tourney_date\"] + ([\"match_num\"] if \"match_num\" in df.columns else [])\n",
    "    df = df.sort_values(sort_cols).reset_index(drop=True)\n",
    "\n",
    "    k_by_year = [(2022, 64.0), (2018, 48.0), (2010, 40.0), (2000, 32.0)]\n",
    "    def K_for_year(year):\n",
    "        for y0, kval in k_by_year:\n",
    "            if year >= y0: return float(kval)\n",
    "        return 48.0\n",
    "\n",
    "    def best_of_mult(row): return 1.25 if row.get(\"best_of\", 3) == 5 else 1.0\n",
    "    def level_mult(row):\n",
    "        lvl = str(row.get(\"tourney_level\", \"\"))\n",
    "        return 1.25 if lvl==\"G\" else 1.15 if lvl==\"M\" else 1.05 if lvl==\"A\" else 1.0\n",
    "\n",
    "    elo = defaultdict(lambda: base)\n",
    "    w_pre, l_pre = [], []\n",
    "    current_year = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        y = int(str(row[\"tourney_date\"])[:4])\n",
    "        if current_year is None: current_year = y\n",
    "        if y != current_year:\n",
    "            for pid in list(elo.keys()):\n",
    "                elo[pid] = base + rho * (elo[pid] - base)\n",
    "            current_year = y\n",
    "\n",
    "        wid, lid = row[\"winner_id\"], row[\"loser_id\"]\n",
    "        ew, el = elo[wid], elo[lid]\n",
    "        w_pre.append(ew); l_pre.append(el)\n",
    "\n",
    "        pw = 1.0 / (1.0 + 10 ** ((el - ew) / 400.0))\n",
    "        K = K_for_year(y) * best_of_mult(row) * level_mult(row)\n",
    "\n",
    "        elo[wid] = ew + K * (1 - pw)\n",
    "        elo[lid] = el + K * (0 - (1 - pw))\n",
    "\n",
    "    df[\"winner_elo_pre\"] = w_pre\n",
    "    df[\"loser_elo_pre\"]  = l_pre\n",
    "    return df\n",
    "\n",
    "def add_surface_elo(df, base=1500.0, rho=0.85, k_surface_scale=0.70):\n",
    "    df = df.copy()\n",
    "    sort_cols = [\"tourney_date\"] + ([\"match_num\"] if \"match_num\" in df.columns else [])\n",
    "    df = df.sort_values(sort_cols).reset_index(drop=True)\n",
    "\n",
    "    k_by_year = [(2022, 48.0), (2018, 36.0), (2010, 32.0), (2000, 24.0)]\n",
    "    def K_for_year(year):\n",
    "        for y0, kval in k_by_year:\n",
    "            if year >= y0: return float(kval)\n",
    "        return 32.0\n",
    "\n",
    "    def best_of_mult(row): return 1.25 if row.get(\"best_of\", 3) == 5 else 1.0\n",
    "    def level_mult(row):\n",
    "        lvl = str(row.get(\"tourney_level\", \"\"))\n",
    "        return 1.25 if lvl==\"G\" else 1.15 if lvl==\"M\" else 1.05 if lvl==\"A\" else 1.0\n",
    "\n",
    "    selo = defaultdict(lambda: base)\n",
    "    w_pre, l_pre = [], []\n",
    "    current_year = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        y = int(str(row[\"tourney_date\"])[:4])\n",
    "        if current_year is None: current_year = y\n",
    "        if y != current_year:\n",
    "            for key in list(selo.keys()):\n",
    "                selo[key] = base + rho * (selo[key] - base)\n",
    "            current_year = y\n",
    "\n",
    "        surf = str(row.get(\"surface\", \"UNK\"))\n",
    "        wid, lid = row[\"winner_id\"], row[\"loser_id\"]\n",
    "        ew, el = selo[(wid, surf)], selo[(lid, surf)]\n",
    "        w_pre.append(ew); l_pre.append(el)\n",
    "\n",
    "        pw = 1.0 / (1.0 + 10 ** ((el - ew) / 400.0))\n",
    "        K = K_for_year(y) * k_surface_scale * best_of_mult(row) * level_mult(row)\n",
    "\n",
    "        selo[(wid, surf)] = ew + K * (1 - pw)\n",
    "        selo[(lid, surf)] = el + K * (0 - (1 - pw))\n",
    "\n",
    "    df[\"winner_surfelo_pre\"] = w_pre\n",
    "    df[\"loser_surfelo_pre\"]  = l_pre\n",
    "    return df\n",
    "\n",
    "df = add_date_features(df)\n",
    "df = add_global_elo(df)\n",
    "df = add_surface_elo(df)\n",
    "\n",
    "df = add_lastN_overall_and_surface(df, k=3)\n",
    "df = add_lastN_overall_and_surface(df, k=10)\n",
    "\n",
    "print(\"Features built. Example cols:\", [c for c in df.columns if \"elo\" in c][:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f35e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair rows: 149812 Date range: 20000103 to 20241218\n"
     ]
    }
   ],
   "source": [
    "def build_pairwise_dataset(df):\n",
    "    base = df.copy()\n",
    "\n",
    "    cols_p = {\n",
    "        \"age\": (\"winner_age\", \"loser_age\"),\n",
    "        \"ht\": (\"winner_ht\", \"loser_ht\"),\n",
    "        \"rank\": (\"winner_rank\", \"loser_rank\"),\n",
    "        \"rank_points\": (\"winner_rank_points\", \"loser_rank_points\"),\n",
    "        \"ioc\": (\"winner_ioc\", \"loser_ioc\"),\n",
    "        \"hand\": (\"winner_hand\", \"loser_hand\"),\n",
    "        \"last3_wr\": (\"winner_last3_wr\", \"loser_last3_wr\"),\n",
    "        \"last3_n\": (\"winner_last3_n\", \"loser_last3_n\"),\n",
    "        \"elo\": (\"winner_elo_pre\", \"loser_elo_pre\"),\n",
    "        \"surfelo\": (\"winner_surfelo_pre\", \"loser_surfelo_pre\"),\n",
    "        \"last10_wr\": (\"winner_last10_wr\", \"loser_last10_wr\"),\n",
    "        \"last10_n\": (\"winner_last10_n\", \"loser_last10_n\"),\n",
    "        \"surf_last10_wr\": (\"winner_surf_last10_wr\", \"loser_surf_last10_wr\"),\n",
    "        \"surf_last10_n\": (\"winner_surf_last10_n\", \"loser_surf_last10_n\"),\n",
    "    }\n",
    "\n",
    "    def make_view(swap=False):\n",
    "        out = pd.DataFrame(index=base.index)\n",
    "        for c in [\"surface\", \"tourney_level\", \"best_of\", \"round\", \"tourney_date\", \"match_num\"]:\n",
    "            if c in base.columns:\n",
    "                out[c] = base[c]\n",
    "\n",
    "        # medtag dato-features her\n",
    "        out[\"date_year\"] = base[\"date_year\"]\n",
    "        out[\"date_doy\"]  = base[\"date_doy\"]\n",
    "\n",
    "        for name, (cw, cl) in cols_p.items():\n",
    "            if not swap:\n",
    "                out[f\"p1_{name}\"] = base[cw]\n",
    "                out[f\"p2_{name}\"] = base[cl]\n",
    "            else:\n",
    "                out[f\"p1_{name}\"] = base[cl]\n",
    "                out[f\"p2_{name}\"] = base[cw]\n",
    "        out[\"y\"] = 1 if not swap else 0\n",
    "        return out\n",
    "\n",
    "    return pd.concat([make_view(False), make_view(True)], ignore_index=True)\n",
    "\n",
    "def elo_prob_from_diff(diff):\n",
    "    return 1.0 / (1.0 + 10 ** (-diff / 400.0))\n",
    "\n",
    "pair = build_pairwise_dataset(df)\n",
    "\n",
    "# diff-features (matcher jeres PyTorch-tanke)\n",
    "pair[\"diff_age\"]         = pair[\"p1_age\"] - pair[\"p2_age\"]\n",
    "pair[\"diff_ht\"]          = pair[\"p1_ht\"]  - pair[\"p2_ht\"]\n",
    "pair[\"diff_rank\"]        = pair[\"p1_rank\"] - pair[\"p2_rank\"]\n",
    "pair[\"diff_rank_points\"] = pair[\"p1_rank_points\"] - pair[\"p2_rank_points\"]\n",
    "\n",
    "pair[\"diff_last3_wr\"] = pair[\"p1_last3_wr\"] - pair[\"p2_last3_wr\"]\n",
    "pair[\"diff_last3_n\"]  = pair[\"p1_last3_n\"]  - pair[\"p2_last3_n\"]\n",
    "\n",
    "pair[\"diff_elo\"]     = pair[\"p1_elo\"] - pair[\"p2_elo\"]\n",
    "pair[\"diff_surfelo\"] = pair[\"p1_surfelo\"] - pair[\"p2_surfelo\"]\n",
    "pair[\"elo_p\"]        = elo_prob_from_diff(pair[\"diff_elo\"])\n",
    "pair[\"surfelo_p\"]    = elo_prob_from_diff(pair[\"diff_surfelo\"])\n",
    "\n",
    "pair[\"diff_last10_wr\"] = pair[\"p1_last10_wr\"] - pair[\"p2_last10_wr\"]\n",
    "pair[\"diff_last10_n\"]  = pair[\"p1_last10_n\"]  - pair[\"p2_last10_n\"]\n",
    "\n",
    "pair[\"diff_surf_last10_wr\"] = pair[\"p1_surf_last10_wr\"] - pair[\"p2_surf_last10_wr\"]\n",
    "pair[\"diff_surf_last10_n\"]  = pair[\"p1_surf_last10_n\"]  - pair[\"p2_surf_last10_n\"]\n",
    "\n",
    "print(\"Pair rows:\", len(pair), \"Date range:\", pair[\"tourney_date\"].min(), \"to\", pair[\"tourney_date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc726927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 143660 Test rows: 6152\n",
      "Test date range: 20240101 - 20241218\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [\"surface\",\"tourney_level\",\"best_of\",\"round\",\n",
    "            \"p1_ioc\",\"p2_ioc\",\"p1_hand\",\"p2_hand\"]\n",
    "\n",
    "num_cols = [\n",
    "    \"diff_age\",\"diff_ht\",\"diff_rank\",\"diff_rank_points\",\n",
    "    \"diff_last3_wr\",\"diff_last3_n\",\n",
    "    \"diff_elo\",\"diff_surfelo\",\"elo_p\",\"surfelo_p\",\n",
    "    \"date_year\",\"date_doy\",\n",
    "    \"diff_last10_wr\",\"diff_last10_n\",\n",
    "    \"diff_surf_last10_wr\",\"diff_surf_last10_n\",\n",
    "]\n",
    "\n",
    "X = pair[cat_cols + num_cols]\n",
    "y = pair[\"y\"].astype(int)\n",
    "\n",
    "train_mask = pair[\"tourney_date\"] < 20240101\n",
    "test_mask  = (pair[\"tourney_date\"] >= 20240101) & (pair[\"tourney_date\"] < 20250101)\n",
    "\n",
    "print(\"Train rows:\", train_mask.sum(), \"Test rows:\", test_mask.sum())\n",
    "print(\"Test date range:\", pair.loc[test_mask, \"tourney_date\"].min(), \"-\", pair.loc[test_mask, \"tourney_date\"].max())\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test,  y_test  = X[test_mask],  y[test_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9dff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained + saved.\n"
     ]
    }
   ],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=18,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf_model = Pipeline([(\"prep\", preprocess), (\"rf\", rf)])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# gem modellen (så kan du teste senere uden at træne igen)\n",
    "joblib.dump(rf_model, \"x_RF_tennis.joblib\", compress=3)\n",
    "print(\"Model trained + saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f52880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.6518205461638491\n",
      "AUC: 0.7162738792378935\n",
      "LogLoss: 0.6146389533595797\n",
      "[[2002 1074]\n",
      " [1068 2008]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      3076\n",
      "           1       0.65      0.65      0.65      3076\n",
      "\n",
      "    accuracy                           0.65      6152\n",
      "   macro avg       0.65      0.65      0.65      6152\n",
      "weighted avg       0.65      0.65      0.65      6152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, confusion_matrix, classification_report\n",
    "\n",
    "proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"ACC:\", accuracy_score(y_test, pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, proba))\n",
    "print(\"LogLoss:\", log_loss(y_test, proba))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51ddcb",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c5104da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = pair[\"tourney_date\"] < 20230101\n",
    "val_mask   = (pair[\"tourney_date\"] >= 20230101) & (pair[\"tourney_date\"] < 20240101)\n",
    "test_mask  = (pair[\"tourney_date\"] >= 20240101) & (pair[\"tourney_date\"] < 20250101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a9b7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = preprocess.fit_transform(X[train_mask])\n",
    "ytr = y[train_mask].to_numpy()\n",
    "\n",
    "Xva = preprocess.transform(X[val_mask])\n",
    "yva = y[val_mask].to_numpy()\n",
    "\n",
    "Xte = preprocess.transform(X[test_mask])\n",
    "yte = y[test_mask].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "445bd489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebhj\\miniforge3\\envs\\intelligent-systems\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:35:03] WARNING: D:\\bld\\xgboost-split_1737531311373\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\sebhj\\miniforge3\\envs\\intelligent-systems\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:35:11] WARNING: D:\\bld\\xgboost-split_1737531311373\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_tennis_pipeline.joblib']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=2,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "\n",
    "    # GPU\n",
    "    tree_method=\"gpu_hist\",\n",
    "    device = \"cuda\"\n",
    ")\n",
    "\n",
    "xgb_model = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"xgb\", xgb_clf)\n",
    "])\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(xgb_model, \"xgb_tennis_pipeline.joblib\", compress=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c0601e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB ACC: 0.6532834850455137\n",
      "XGB AUC: 0.7219994956549383\n",
      "XGB LogLoss: 0.6105772282944976\n",
      "[[2006 1070]\n",
      " [1063 2013]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      3076\n",
      "           1       0.65      0.65      0.65      3076\n",
      "\n",
      "    accuracy                           0.65      6152\n",
      "   macro avg       0.65      0.65      0.65      6152\n",
      "weighted avg       0.65      0.65      0.65      6152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# sandsynlighed for klasse 1 (p1 vinder i pairwise setup)\n",
    "p_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "pred  = (p_xgb >= 0.5).astype(int)\n",
    "\n",
    "print(\"XGB ACC:\", accuracy_score(y_test, pred))\n",
    "print(\"XGB AUC:\", roc_auc_score(y_test, p_xgb))\n",
    "print(\"XGB LogLoss:\", log_loss(y_test, p_xgb))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd8ee3",
   "metadata": {},
   "source": [
    "Ensemble: stemme / gennemsnit af sandsynligheder (mest almindeligt)\n",
    "\n",
    "Du træner både Random Forest og XGBoost hver for sig, og kombinerer deres output:\n",
    "\n",
    "soft voting: gennemsnit af predict_proba\n",
    "\n",
    "hard voting: flertalsafstemning på klasser\n",
    "\n",
    "Soft voting er næsten altid bedst, især når du vil have gode sandsynligheder (odds/betting).\n",
    "\n",
    "\n",
    "\n",
    "eller med vægte (fx 0.3/0.7) baseret på validering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94950da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF ACC: 0.6518205461638491\n",
      "RF AUC: 0.7162738792378935\n",
      "RF LogLoss: 0.6146389533595797\n",
      "\n",
      "XGB ACC: 0.6532834850455137\n",
      "XGB AUC: 0.7219994956549383\n",
      "XGB LogLoss: 0.6105772282944976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "p_rf  = rf_model.predict_proba(X_test)[:, 1]\n",
    "p_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def eval_probs(y_true, p, name=\"MODEL\"):\n",
    "    pred = (p >= 0.5).astype(int)\n",
    "    print(f\"{name} ACC:\", accuracy_score(y_true, pred))\n",
    "    print(f\"{name} AUC:\", roc_auc_score(y_true, p))\n",
    "    print(f\"{name} LogLoss:\", log_loss(y_true, p))\n",
    "    print()\n",
    "\n",
    "# Individuelle\n",
    "eval_probs(y_test, p_rf,  \"RF\")\n",
    "eval_probs(y_test, p_xgb, \"XGB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b25fe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best w (min LogLoss): 0.7000000000000001 LogLoss: 0.6089793309487922\n"
     ]
    }
   ],
   "source": [
    "best = None\n",
    "for w in np.linspace(0, 1, 21):  \n",
    "    p = (1 - w) * p_rf + w * p_xgb\n",
    "    ll = log_loss(y_test, p)\n",
    "    if best is None or ll < best[0]:\n",
    "        best = (ll, w)\n",
    "\n",
    "print(\"Best w (min LogLoss):\", best[1], \"LogLoss:\", best[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d10d72bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENS ACC: 0.6553966189856957\n",
      "ENS AUC: 0.7224162778742595\n",
      "ENS LogLoss: 0.6089793304979688\n"
     ]
    }
   ],
   "source": [
    "w = 0.7\n",
    "p_ens = (1 - w) * p_rf + w * p_xgb\n",
    "pred_ens = (p_ens >= 0.5).astype(int)\n",
    "\n",
    "print(\"ENS ACC:\", accuracy_score(y_test, pred_ens))\n",
    "print(\"ENS AUC:\", roc_auc_score(y_test, p_ens))\n",
    "print(\"ENS LogLoss:\", log_loss(y_test, p_ens))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
